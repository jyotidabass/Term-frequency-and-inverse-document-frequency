{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ff35ca",
   "metadata": {
    "papermill": {
     "duration": 0.003383,
     "end_time": "2024-09-11T16:34:04.257408",
     "exception": false,
     "start_time": "2024-09-11T16:34:04.254025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is TF-IDF (Term Frequency-Inverse Document Frequency)? \n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic that reflects how important a word is to a document in a collection or corpus of documents. In the finance domain, it can be used to analyze and compare the relative importance of financial terms across different financial reports or documents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a19d0",
   "metadata": {
    "papermill": {
     "duration": 0.00273,
     "end_time": "2024-09-11T16:34:04.263045",
     "exception": false,
     "start_time": "2024-09-11T16:34:04.260315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Here's a simple Python code snippet using the popular scikit-learn library to perform TF-IDF analysis on a given collection of documents. \n",
    "\n",
    "**First, you'll need to install the required libraries if they are not already installed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8b4ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T16:34:04.270891Z",
     "iopub.status.busy": "2024-09-11T16:34:04.269977Z",
     "iopub.status.idle": "2024-09-11T16:34:07.734985Z",
     "shell.execute_reply": "2024-09-11T16:34:07.733939Z"
    },
    "papermill": {
     "duration": 3.471711,
     "end_time": "2024-09-11T16:34:07.737475",
     "exception": false,
     "start_time": "2024-09-11T16:34:04.265764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Collecting sklearn\r\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \berror\r\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\r\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\r\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\r\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\r\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\r\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\r\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\r\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\r\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\r\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m More information is available at\r\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\r\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\r\n",
      "\r\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\r\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\r\n",
      "\r\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\r\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40076f4f",
   "metadata": {
    "papermill": {
     "duration": 0.003185,
     "end_time": "2024-09-11T16:34:07.744338",
     "exception": false,
     "start_time": "2024-09-11T16:34:07.741153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Now, let's assume you have a list of documents in a variable named documents. In this example, we'll work with a simple list of three documents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee02557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T16:34:07.752362Z",
     "iopub.status.busy": "2024-09-11T16:34:07.752008Z",
     "iopub.status.idle": "2024-09-11T16:34:07.757108Z",
     "shell.execute_reply": "2024-09-11T16:34:07.756198Z"
    },
    "papermill": {
     "duration": 0.011377,
     "end_time": "2024-09-11T16:34:07.758993",
     "exception": false,
     "start_time": "2024-09-11T16:34:07.747616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Document 1: This is the first document.\",\n",
    "    \"Document 2: This is the second document.\",\n",
    "    \"Document 3: This is the third document.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec4b2d",
   "metadata": {
    "papermill": {
     "duration": 0.003093,
     "end_time": "2024-09-11T16:34:07.765274",
     "exception": false,
     "start_time": "2024-09-11T16:34:07.762181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Next, you'll need to preprocess the documents, tokenize them, and calculate the TF-IDF scores using scikit-learn.**\n",
    "\n",
    "*This code will output the TF-IDF scores for each term in each document.\n",
    "In this example, the three documents contain the same terms, so the TF-IDF scores will be the same for each term. The output will look something like this:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4a2e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T16:34:07.773153Z",
     "iopub.status.busy": "2024-09-11T16:34:07.772805Z",
     "iopub.status.idle": "2024-09-11T16:34:09.233641Z",
     "shell.execute_reply": "2024-09-11T16:34:09.232114Z"
    },
    "papermill": {
     "duration": 1.467308,
     "end_time": "2024-09-11T16:34:09.235902",
     "exception": false,
     "start_time": "2024-09-11T16:34:07.768594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF scores for Document 1: This is the first document.\n",
      "document: 0.6367\n",
      "first: 0.5390\n",
      "is: 0.3184\n",
      "second: 0.0000\n",
      "the: 0.3184\n",
      "third: 0.0000\n",
      "this: 0.3184\n",
      "\n",
      "TF-IDF scores for Document 2: This is the second document.\n",
      "document: 0.6367\n",
      "first: 0.0000\n",
      "is: 0.3184\n",
      "second: 0.5390\n",
      "the: 0.3184\n",
      "third: 0.0000\n",
      "this: 0.3184\n",
      "\n",
      "TF-IDF scores for Document 3: This is the third document.\n",
      "document: 0.6367\n",
      "first: 0.0000\n",
      "is: 0.3184\n",
      "second: 0.0000\n",
      "the: 0.3184\n",
      "third: 0.5390\n",
      "this: 0.3184\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the documents\n",
    "tfidf_matrix = tfidf.fit_transform(documents)\n",
    "\n",
    "# Access the feature names (terms)\n",
    "terms = tfidf.get_feature_names_out() # Changed to get_feature_names_out()\n",
    "\n",
    "# Access the TF-IDF matrix\n",
    "tfidf_array = np.array(tfidf_matrix.todense())\n",
    "\n",
    "# Print the terms and their corresponding TF-IDF scores for each document\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\nTF-IDF scores for {doc}\")\n",
    "    for j, term in enumerate(terms):\n",
    "        print(f\"{term}: {tfidf_array[i, j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff0ce1",
   "metadata": {
    "papermill": {
     "duration": 0.003505,
     "end_time": "2024-09-11T16:34:09.243031",
     "exception": false,
     "start_time": "2024-09-11T16:34:09.239526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Please upvote if you liked this!! Thanks!!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.741533,
   "end_time": "2024-09-11T16:34:09.665544",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-11T16:34:00.924011",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
